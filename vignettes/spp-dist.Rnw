<<echo=false>>=
options(width=70)
options(continue=" ")
@

\documentclass[a4paper]{article}
\usepackage[OT1]{fontenc}
\usepackage{Sweave}
\usepackage[authoryear,round]{natbib}
\usepackage{fullpage}
\usepackage{verbatim}

\usepackage[a4paper, hmargin={2cm,2cm}, vmargin={2cm,2cm}]{geometry}


\bibliographystyle{ecology}

\DefineVerbatimEnvironment{Sinput}{Verbatim} {xleftmargin=2em}
\DefineVerbatimEnvironment{Soutput}{Verbatim}{xleftmargin=2em}
\DefineVerbatimEnvironment{Scode}{Verbatim}{xleftmargin=2em}
\fvset{listparameters={\setlength{\topsep}{0pt}}}
\renewenvironment{Schunk}{\vspace{\topsep}}{\vspace{\topsep}}

%%\VignetteIndexEntry{Species distributions}

\title{Modeling and mapping species distributions}
\author{Richard Chandler}


\begin{document}

\maketitle

\abstract{
A species' distribution can be characterized by either
occurrence probability or population density, defined for all
locations in some spatial domain. Defining distribution in terms of
these two parameters %These definitions of species distribution
avoids the ambiguity surrounding the indices of occurrence
or abundance produced by many presence-only algorithms. The
\texttt{unmarked} package contains methods of fitting
occurrence and abundance models, and can be used to
produce distribution maps with the help of \textbf{R}'s GIS
capabilities,
%, such as the \texttt{raster} package
%\citep{hijmans_vanEtten:2012}
as is demonstrated in this vignette.
Unlike many other tools for modeling
species distributions, the models in \texttt{unmarked} account for
bias due to spatial and temporal heterogeneity in detection
probability. Furthermore, \texttt{unmarked} includes models
of population dynamics, allowing one to map quantities
such as local colonization or extinction probability.
}


<<echo=false>>=
library(unmarked)
library(raster)
@


\section*{Mapping Occurrence Probability}



In this example, we use the verb+occu+ function to fit the
single-season occupancy model of
\citep{mackenzie_estimating_2002} to data on the European crossbill
(\emph{Loxia curvirostra}) collected in 267 1-km$^2$ sample
quadrats in Switzerland, 1999 \citep{schmid_etal:2004}.
We then use the model to compute the expected probability of
occurrence at each pixel in a raster defining the Swiss
landscape.

First we load the \verb+crossbill+ data, which contains the
detection/non-detection data and covariates. The dataset actually
contains data from multiple years, but we are only going to analyze
data from the first year, 1999. A multi-year analysis of occupancy
dynamics could be accomplished using the \verb+colext+ function, and
in addition to mapping occurrence probability, it would be possible to
also map colonization and extinction probabilities. The following
commands format the data.

<<>>=
data(crossbill)
umf <- unmarkedFrameOccu(
    y=as.matrix(crossbill[,c("det991", "det992", "det993")]),
    siteCovs=crossbill[,c("ele", "forest")],
    obsCovs=list(date=crossbill[,c("date991", "date992", "date993")]))
sc <- scale(siteCovs(umf))
siteCovs(umf) <- sc
summary(umf)
@

Notice that the site covariates, elevation and forest, were
standardized using the \verb+scale+ function. Standardization isn't
always necessary, but it can make it easier to find the maximum
likelihood estimates. When standardizing covariates and then making
predictions, it is important to retain the original sample mean and
standard deviation. The reason for this is explained below.

Fitting a model is now straight-forward. In many cases, we would fit
several models corresponding to competing hypotheses, but for
simplicity, we stick with this single model.

<<>>=
(fm.occu <- occu(~date ~ele + I(ele^2) + forest, umf))
@

Now that we have our fitted model, we can use it to predict occurrence
probability at each pixel in the Swiss landscape. The \verb+Switzerland+
dataset contains country-wide data. There are many ways to display
it---here is an example of mapping elevation using the
\verb+levelplot+ function in the \texttt{lattice} package.

<<fig=TRUE>>=
data(Switzerland)
print(levelplot(elevation ~ x + y, Switzerland, aspect="iso",
                xlab="Easting (m)", ylab="Northing (m)",
                col.regions=terrain.colors(100)))
@

The \texttt{raster} package \citep{hijmans_vanEtten:2012}
provides another alternative. Here we create two raster objects and
specify the coordinate system.

<<>>=
library(raster)
elevation <- rasterFromXYZ(Switzerland[,c("x","y","elevation")],
    crs="+proj=somerc +lat_0=46.95240555555556 +lon_0=7.439583333333333 +k_0=1 +x_0=600000 +y_0=200000 +ellps=bessel +towgs84=674.374,15.056,405.346,0,0,0,0 +units=m +no_defs")

forest <- rasterFromXYZ(Switzerland[,c("x","y","forest")],
    crs="+proj=somerc +lat_0=46.95240555555556 +lon_0=7.439583333333333 +k_0=1 +x_0=600000 +y_0=200000 +ellps=bessel +towgs84=674.374,15.056,405.346,0,0,0,0 +units=m +no_defs")
@

Since we standardized the covariates during the model fitting process,
we need to transform the country-wide data using the same
values. Note, we don't want to use the mean and SD of the rasters
themselves, we want to use the mean and SD of the original covariates
used to fit the models, which are stored as attributes of the
\verb+sc+ object. The following commands display the original means
and SDs and then transform the rasters and join them in a raster
``stack.''

<<ef,fig=TRUE,include=FALSE,height=3,width=7>>=
attr(sc, "scaled:center")
attr(sc, "scaled:scale")
ele.s <- (elevation-1189)/640
forest.s <- (forest-34.7)/27.7
ef <- stack(ele.s, forest.s)
layerNames(ef) <- c("ele", "forest")
plot(ef, col=terrain.colors(100))
@
\begin{figure}
  \centering
  \includegraphics[width=7in,height=3in]{spp-dist-ef}
  \caption{Elevation and forest cover, standardized.}
\label{fig:psi1}
\end{figure}

Note, it is important to assign \verb+layerNames+ to the raster stack
that exactly match the covariate names used to fit the model. This
is required by the \verb+predict+ function.
The \verb+predict+ function is useful for computing
spatially-referenced model predictions, standard errors, and
confidence intervals, but it is computationally demanding when
there are many pixels in the raster. Thus, if measures of uncertainty
are not required, the following code can be used to quickly produce
the species distribution map shown in Fig.\ref{fig:psi1}.

<<psi,fig=TRUE,include=FALSE>>=
(beta <- coef(fm.occu, type="state"))
logit.psi <- beta[1] + beta[2]*ele.s + beta[3]*ele.s^2 + beta[4]*forest.s
psi <- exp(logit.psi) / (1 + exp(logit.psi))
#plot(psi, col=terrain.colors(100))
print(spplot(psi, col.regions=terrain.colors(100)))
@
\begin{figure}
  \includegraphics[width=4in,height=4in]{spp-dist-psi}
  \centering
  \caption{A species distribution map for the European crossbill in
    Switzerland. The colors represent occurrence probability.}
\label{fig:psi1}
\end{figure}

As of version 0.9-6, the \verb+predict+ method in \texttt{unmarked}
can make predictions using an object of class \verb+RasterStack+ from the
\texttt{raster} package. As mentioned previously, the rasters must be
named, perhaps by using the \verb+layerNames(someraster) <- somename+
method. The object
returned by \verb+predict+ is another raster stack with rasters for
the expected values of the parameter of interest, the standard errors,
and the upper and lower confidence intervals. The following example
is very slow because there are many of pixels in the raster. The
resulting map is shown in Fig.\ref{fig:predict}.

<<psi2,eval=false,echo=false,fig=TRUE,include=FALSE>>=
E.psi <- predict(fm.occu, type="state", newdata=ef)
plot(E.psi, axes=FALSE, col=terrain.colors(100))
@
\begin{Schunk}
\begin{Sinput}
> E.psi <- predict(fm, type="state", newdata=ef)
\end{Sinput}
\begin{Sinput}
> plot(E.psi, axes=FALSE, col=terrain.colors(100))
\end{Sinput}
\end{Schunk}
\begin{figure}[b!]
  \centering
\includegraphics[width=5in,height=5in]{spp-dist-psi}
\caption{Expected occurrence probability along with standard errors
  and the limits of the asymptotic 95\% confidence interval.}
\label{fig:predict}
\end{figure}

Users should be cautious when predicting from models that have
categorical predictor variables, \emph{i.e.} \verb+factor+s. The
\texttt{raster} package does not have advanced methods for handling
factors, and thus it is not easy to automatically create dummy
variables from them as can typically be done using
\verb+model.matrix+. The safest option is to create the dummy
variables manually before fitting the models, and to use the same
variables as rasters for prediction.

A more important consideration when creating species distribution maps
based upon occurrence probability is that of spatial scale.

\section*{Mapping Population Density}

Although distribution is typically described in terms of
ocurrence probability, density is a better descriptor for several
reasons. First, density can be readily converted to abundance for any
region of interest; whereas occurrence probability does not scale with
area.



<<fig=TRUE,width=6,height=4>>=
data(issj)
data(cruz)

elev <- rasterFromXYZ(cruz[,c("x","y","elevation")],
     crs="+proj=utm +zone=11 +ellps=GRS80 +datum=NAD83 +units=m +no_defs")

#plot(elev, col=terrain.colors(100))
#points(issj[,c("x","y")], cex=0.5)

print(
wireframe(elevation ~ x + y, cruz, drape=TRUE,
          screen=list(z=10, x=-10),
          aspect=0.5, xlab="", ylab="", zlab="",
#          xlim=c(229900,267000), ylim=c(3762000,3770000),
          par.settings = list(axis.line = list(col = "transparent")),
          par.box = c(col = "transparent"),
          col.regions=terrain.colors(100),
          colorkey=FALSE)
)

@




<<>>=
covs <- scale(issj[,c("elevation", "forest", "chaparral")])

area <- pi*300^2 / 10000


jayumf <- unmarkedFrameDS(y=as.matrix(issj[,1:3]),
                          siteCovs=data.frame(covs, area),
                          dist.breaks=c(0,100,200,300),
                          unitsIn="m", survey="point")
head(jayumf)

fm1 <- distsamp(~chaparral ~chaparral + elevation + offset(log(area)),
                jayumf, output="abund")
fm1

@

<<>>=

elev <- rasterFromXYZ(cruz[,c("x","y","elevation")],
     crs="+proj=utm +zone=11 +ellps=GRS80 +datum=NAD83 +units=m +no_defs")
forest <- rasterFromXYZ(cruz[,c("x","y","forest")],
     crs="+proj=utm +zone=11 +ellps=GRS80 +datum=NAD83 +units=m +no_defs")
chap <- rasterFromXYZ(cruz[,c("x","y","chaparral")],
     crs="+proj=utm +zone=11 +ellps=GRS80 +datum=NAD83 +units=m +no_defs")
area.raster <- chap
values(area.raster) <- 300*300/10000 # area of a grid pixel

attr(covs, "scaled:center")
attr(covs, "scaled:scale")

elev.s <- (elev-202)/125
forest.s <- (forest-0.0673)/0.137
chap.s <- (chap-0.270)/0.234


habitat <- stack(elev.s, forest.s, chap.s, area.raster)
layerNames(habitat) <- c("elevation", "forest", "chaparral", "area")


@




<<fig=TRUE>>=
E <- predict(fm1, type="state", newdata=habitat)
plot(E)

cellStats(E[["Predicted"]], "sum")

@






<<echo=FALSE>>=
detach(package:raster)
@



\newpage

\bibliography{unmarked}

\end{document}
