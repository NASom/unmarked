%% use
%% library(cacheSweave)
%% Sweave("unmarked.Rnw", driver = cacheSweaveDriver)

<<echo=FALSE>>=
options(device.ask.default=FALSE)
options(width=70)
@ 

\documentclass[article,shortnames]{jss}
\usepackage{amsmath,amssymb}
\usepackage[utf8]{inputenc}
\usepackage{rotating}
\usepackage{float}
%% need no \usepackage{Sweave.sty}


\DeclareMathOperator{\logit}{logit}
\DeclareMathOperator{\Bern}{Bernoulli}
\DeclareMathOperator{\Bin}{Binomial}
\DeclareMathOperator{\Poi}{Poisson}
\DeclareMathOperator{\MN}{Multinomial}

\newcommand{\um}{\pkg{unmarked}}
\newcommand{\rlang}{\proglang{R}}
\newcommand{\scovs}{\code{siteCovs}}
\newcommand{\ocovs}{\code{obsCovs}}

\author{Ian J. Fiske\\North Carolina State University \And
  Richard Chandler\\ USGS Patuxent Wildlife Research Center}
\title{\pkg{unmarked}:\\
  An \proglang{R} package for the Analysis of Wildlife Occurrence and Abundance Data}

\Plainauthor{Ian Fiske, Richard Chandler}
\Plaintitle{unmarked: An R Package for the Analysis of Wildlife
  Occurrence and Abundance Data}
\Shorttitle{\um: Analyze Wildlife Data in \proglang{R}}

\Abstract{Ecological research uses data collection techniques that are prone to 
substantial and unique types of measurement error to address scientific 
questions about species abundance and distribution.  These data collection 
schemes include a number of survey methods in which unmarked individuals are 
counted, or determined to be present, at numerous spatially-referenced sites.  
Examples include site occupancy sampling, repeated counts, distance sampling, 
removal sampling, and double observer sampling.  To appropriately analyze these 
data, hierarchical models have been developed that can separately model 
explanatory variables of both a latent abundance process and a conditional 
detection process.  Because these models have a straightforward interpretation 
paralleling how the data arose, they have recently gained immense popularity.  
The common hierarchical structure of these models is well-suited for a unified 
modeling interface.  The \proglang{R} package \pkg{unmarked} provides such a 
unified modeling framework, including tools for data exploration, model fitting, 
model criticism, post-hoc analysis, and model comparison.}

\Keywords{ecological, wildlife, hierarchical, occupancy, occurrence, distance, point count}
\Plainkeywords{ecological, wildlife, hierarchical, occupancy, occurrence, distance, point count}


\Address{
Ian Fiske\\
Department of Statistics\\
North Carolina State University\\
2311 Stinson Drive \\
Campus Box 8203 \\
Raleigh, NC 27695-8203 \\
E-mail: \email{ijfiske@ncsu.edu}

Richard Chandler \\   
USGS Patuxent Wildlife Research Center \\
Gabrielson Lab, Room 226 \\
12100 Beech Forest Rd. \\
Laurel, MD 20708 \\
E-mail: \email{rchandler@usgs.gov} 
}



\begin{document}


\section{Introduction}


\subsection{Imperfect detection in ecological research}

A fundamental goal of ecological research is to understand how environmental 
variables influence species abundance or occurrence.  Addressing these 
research questions is complicated by imperfect detection proability.  A 
species may go undetected when present for a variety of reasons including its 
proximity to the observer, cryptic behavior, or camouflage.  To overcome these 
difficulties, ecologists have developed specialized methods to survey 
wildlife populations such as site occupancy sampling, repeated counts, 
distance sampling, removal sampling, and double observer sampling 
(see Section~\ref{sec:models-impl-unmark} for definitions).  Each of these 
sampling methods involves surveying a collection spatially-referenced `sites', 
which may be distinct habitat patches or arbitrarily-defined plots.  
Observations are generated by a combination of (1) a \emph{state} process 
determining species abundance at each site and (2) a \emph{detection} process 
that yields observations conditional on the abundance.  Historically, 
ecologists ignored the detection process and fit standard generalized linear 
models to such data; however, failure to account for imperfect detection can 
yield grossly biased estimates of abundance or occurrence.  Therefore, the use 
of these specialized survey methods requires statistical models designed to 
appropriately account for both the state and observation processes. Recently 
developed hierarchical models offer a powerful means of analyzing these data 
because they regard site-specific abundance or occurence as a latent variable 
that may be impefectly observed and directly modeled as a function of 
covariates.  This paper introduces \um, an \rlang\ package that provides a 
unified approach for fitting this class of hierarchical models.

\subsection[Scope and features of unmarked]{Scope and features of \pkg{unmarked}} 

\um\ provides tools to assist researchers with every step of the analysis 
process, including data manipulation and exploration, model fitting, post-hoc 
analysis, model criticism, and model selection.  Because of the multi-level 
structure of the data and models, covariate data can exist at both the state 
and detection level.  To succinctly describe these data, \um\ uses a new data 
type called the unmarkedFrame (Section~\ref{sec:data-requirements}).  \um\ 
provides functions that import data from various common formats and convert 
them into \um's data types.  Once imported, \um\ provides functions to 
summarize and subset these data in a manner familiar to users of \rlang's 
more common data structures such as vectors, matrices, and \code{data.frame}. 

\um\ provides a growing list of model-fitting functions designed for specific 
sampling methods.  The fitting functions each find the maximum likelihood 
estimates of parameters from a particular model 
(Section~\ref{sec:fitting-models}) and return an object that can be easily 
manipulated.  Methods exist for performing numerous post-hoc analyses such as 
requesting linear combinations of parameters, back-transforming parameters to 
constrained scales, determining confidence intervals, and evaluating goodness 
of fit.  The model specification syntax of the fitting functions was designed 
to resemble the syntax of \rlang's common fitting functions such as \code{lm} 
for fitting linear models.

Although there is existing software for fitting some of these models 
\citep[e.g.,]{Hines2002}, there are a number of advantages to a unified 
framework within \rlang.  Many researchers are already familiar with \rlang\ 
and use its powerful data manipulation and plotting capabilities.  Sometimes 
many species are analyzed in tandem, so that a common method of aggregating 
and post-processing of results is needed, a task easily accomplished in 
\rlang.  Unlike other available software, \um\ makes it easy to map 
habitat-specific abundance and species distributions when combined with 
\rlang's GIS capabilities.  Another important advantage of \um's approach is 
that researchers can easily simulate and analyze data within the same 
computational environment.  This work flow permits simulation studies for power 
analysis calculations or the effectiveness of future sampling designs.  All of 
this is made much simpler by analyzing the data within \rlang, and using a 
single environment to complete all phases of the analysis is much less 
error-prone than switching between applications. 

In this paper, Section~\ref{sec:models-impl-unmark} gives a brief summary of 
many of the models \um\ is capable of fitting.  
Section~\ref{sec:unmarked-usage} describes general \um\ usage aided by a 
running data example.

\section[Models implemented in unmarked]{Models implemented in \um}
\label{sec:models-impl-unmark}

The list of models implemented in \um\ continues to grow as new models are 
developed. Table~\ref{tab:models} shows the models available as of version 
0.9-0.  Rather than describe each fitting function in detail, this section 
provides a summary of several of the most common sampling techniques and how 
\um\ can be used to model the resulting data. 

\begin{table}[H] \small
%\begin{sidewaystable} \small
\begin{tabular}{cccc}
\hline
\textbf{Model} & \textbf{Fitting function} & \textbf{Data} & \textbf{Citation} \\ \hline
Single-season Occupancy & \code{occu} & unmarkedFrameOccu & \citep{MacKenzie2002} \\
Abundance from presence-absence & \code{occuRN}& unmarkedFrameOccu & \citep{Royle2003} \\
Abundance from repeated counts &\code{pcount}& unmarkedFramePCount & \citep{Royle2004} \\
Distance-sampling &\code{distsamp}& unmarkedFrameDS & \citep{Royle2004b} \\
Multinomial Counts &\code{multinomPois}& unmarkedFrameMPois & \citep{Royle2004a} \\
Repeated Multinomial Counts &\code{gmultmix} & unmarkedFrameGMM & \citep{Royle2004a} \\
Multi-season Occupancy &\code{colext}& unmarkedMultFrame & \citep{MacKenzie2003} \\
Multi-season Abundance & \code{pcountOpen} & unmarkedPCO & \citep{DailMadsen2011} \\
\hline
\end{tabular}
\caption{Models handled by unmarked along with their associated
  fitting functions (Section~\ref{sec:models-impl-unmark}) and data
  type (Section~\ref{sec:data-requirements}).}
\label{tab:models}
%\end{sidewaystable}
\end{table}

\subsection{Single-season Occurrence data} 
\label{sec:occ}

An important estimand in ecological research is the
proportion of sites that are occupied by the study species, called
occupancy probability.  Another related goal is to identify factors that are
associated with the changes in the probability of a site being
occupied.  To estimate these parameters, researchers employ
so-called occurrence sampling, whereby surveyors visit a sample of $M$
sites and record the binary response of species detection (1) or
non-detection (0) during $J_{i}$ visits to the $i$th site during a
`season' \citep{MacKenzie2002}.  The key assumptions made
when modelling these data are that the occupancy state at a site is
assumed to remain constant throughout the season and repeated visits at
a site are independent.  The first assumption is commonly referred to as the
`population closure' assumption, meaning that no births, deaths, movements 
on or off the site are believed to occur during the season.  
Season, therefore, will generally refer to a very short time frame, such as 
a few months during a breeding season, or even a few minutes if repeated 
visits are made in quick succession.  The repeated visits are necessary to 
obtain information about the detection rate separate from the occupancy rate.  

To describe these data, we use the following hierarchical Bernoulli.  
Let $\psi_i$ be the probability of occupancy at site $i$.  And $p_{ij}$ is the
probability of detecting the species at site $i$ during the $j$th
survey occasion given that site $i$ is truly occupied.  More formally,
observations at site $i$ arise as
\begin{gather}
Z_i \sim \Bern(\psi_i) \text{\quad for $i=1,2,\dots,M$} \\
Y_{ij}|Z_i \sim \Bern(Z_i p_{ij})\text{\quad for $j=1,2,\dots,J_{i}$}
\end{gather}
where $Z_i$ is the partially observed occupancy state. Variables that are 
suspected to be related to the occupancy state are modeled as

\begin{gather}
  \logit(\psi_i) = \mathbf x_i' \mathbf \beta,
\end{gather}
where $\mathbf x_i$ is a vector of site-level covariates and $\mathbf \beta$
is a vector of their corresponding effect parameters.  Similarly, the
probability of detection can be modeled with
\begin{gather}
  \logit(p_{ij}) = \mathbf v_{ij}' \mathbf \alpha,
\end{gather}
where $\mathbf v_{ij}$ is a vector of observation-level covariates and
$\mathbf \alpha$ is a vector of their corresponding effect parameters.  
Examples of site-level covariates include habitat characteristics such as 
vegetation height. Observation-level covariates could include time of day, 
date, wind speed, or other factors that might affect detection probability. 

The likelihood for the single-season occupancy model, as maximized by the
\code{occu} function, is

\begin{equation}
L(Y_{ij}| p,\phi) = 
 \prod_{i}^{M} \left\{
    \prod_{j}^{J} 
      \left(p^{Y_{ij}}(1-p)^{1-Y_{ij}}\right)
          \phi + I(Y_{i.}=0)(1-\phi) \right\}. 
\end{equation}

A generalization of this model that relaxes the population closure
assumption is fit by the \code{colext} function, described subsequently.

\subsection{Repeated count data}
\label{sec:repeated-count-data}

Estimates of occupancy rate provide much less information about a
population than do abundance estimates. For instance, suppose the
average number of individuals per site decreases from 10 to 5 during
the course of a multi-season study. This dramatic population decline
would not be detected using occurrence sampling.  One method to
estimate abundance is to repeatedly visit a sample of $M$ sites and
record the number of unique individuals observed at each site.
Similar assumptions are made as with occurrence data: (1) abundance at
a site remains constant during a season and (2) counts at a site are
independent.  \citet{Royle2004} presented the following hierarchical model for
repeated count data.  Let $N_i$ be the unobserved total number of
individuals using a site and define $Y_{ij}$ as the number of individuals 
observed during the $j$th visit.  Then,
\begin{gather}
  N_i \sim f(\lambda_i, \theta) \text{\quad for $i=1,2,\dots,M$} \label{eq:pc2} \\
  Y_{ij}|N_{i} \sim \Bin(N_i, p_{ij})\text{\quad for $j=1,2,\dots,J_{i}$},
\end{gather}
where $\lambda_i$ is the abundance rate at site $i$ and $p_{ij}$ is
the detection probability during the $j$th visit to site $i$.  $f$ is
a discrete distribution with support restricted to $N_{i} \ge 0$ and
$\theta$ are extra parameters of $f$ other than the location
parameter, $\lambda_{i}$.  \um\ currently supports $f$ as Poisson or
negative binomial.  In the Poisson case, there is no $\theta$.  In the
negative binomial case, $\theta$ is a dispersion parameter, which is
useful when overdispersion is suspected.

As with the occupancy model, covariates may be included at either the
state (here, abundance) or detection levels, but abundance is modeled
through a log link to enforce it's positivity constraint.
\begin{gather}
  \log(\lambda_i) = \mathbf x_i' \mathbf \beta,
\end{gather}
where $\mathbf x_i$ is a vector of site-level covariates and $\mathbf \beta$
is a vector of their corresponding effect parameters.  Similarly, the
probability of detection can be modeled with
\begin{gather}
  \logit(p_{ij}) = \mathbf v_{ij}' \mathbf \alpha,
\end{gather}
where $\mathbf v_{ij}$ is a vector of observation-level covariates and
$\mathbf \alpha$ is a vector of their corresponding effect parameters.

\citet{Royle2004b} showed that in the case of the Poisson assumption, 
the integrated likelihood of $Y_{ij}$ is:

\begin{equation}
L(Y_{ij}| p,\lambda) = 
 \prod_{i}^{M} 
 \left\{ \sum_{N_{i}=max({\bf Y_i})}^{\infty}
          \left( \prod_{j}^{J} 
     \frac{N_{i!}}{ (N_{i}-Y_{ij})!} p^{Y_{ij}}(1-p)^{N_{i}-Y_{ij}} \right)
       \frac{e^{-\lambda} \lambda^N}{N!} \right\}.
\end{equation}

This likelihood can be maximized using the \code{pcount} function.  Note that,
because we are using classical methods as opposed to Bayesian methods, 
the latent variable \code{N} must be integrated out of the likelihood, and the
user must choose a finite range for the discrete integration. The upper 
limit of this range can be specified using the \code{K} argument.  It should
be set sufficiently higher than the maximum observed count so that the 
MLEs are not affected.  However, users should be aware that compuatation 
time increases with \code{K}.

Two generalizations of this model can also be fit in \um\ by the 
\code{gmultmix} and \code{pcountOpen} functions.  As with \code{colext},
these functions relax the population closure assumption and allow for 
the modelling of population dynamics.


     
\subsection{General multinomial-Poisson mixture model}
\label{sec:gener-mult-poiss}
Here we discuss a more general class of models that can be modified to fit a
variety of sampling methods, the multinomial-Poisson model
\citep{Royle2004a}.  The general form of this model is
\begin{gather}
  N_i \sim \Poi(\lambda_i) \text{\quad for $i=1,2,\dots,M$} \label{eq:mp2} \\
  \begin{pmatrix}
    \mathbf Y_i\\
    N_{i} - \sum_{j=1}^{J} Y_{ij}
  \end{pmatrix}
  \bigg| N_{i} \sim \MN\left(N_i, 
  \begin{pmatrix}
    \boldsymbol \pi_i \\
    \pi_{i}^{*}
  \end{pmatrix}\right)
\end{gather}
where $N_i$ is the latent abundance at site $i$ as with the repeated
count model, and $\boldsymbol \pi_i=(\pi_{i1},\pi_{i2},\dots,\pi_{iJ})'$ is
the vector of cell probabilities of observing responses in the $J$
possible categories, and $\mathbf Y_{i}$ is the $J$-vector of counts
that were actually observed.  In general, $\boldsymbol \pi_i$ is
determined by the specific sampling method and
$\sum_{j} \pi_{ij} \le 1$ because detection is imperfect and
$\pi_{i}^{*}=1 - \sum_{j} \pi_{ij}$ is the probability of the species
escaping detection at site $i$.  

Suppose that the sampling method yielded three observations at each cite.  
\citet{Royle2004a} demonstrated that if the observations ${\bf Y}_i$ are 
independent when conditioned on local population size $N_i$ and $p_{it}$, the 
integrated likelihood of ${\bf y}_{i}$ is:

\begin{equation}
L({\bf Y}_i| {\bf p},\lambda) = 
 \prod_{i=1}^{N} \left\{ 
  \sum_{M_{i}=0}^{\infty} \left(
 \frac{N_{i}!}{ y_{i1}! y_{i2}! y_{i3}! y_{i0}!}
  \pi_{1}^{y_{i1}}
  \pi_{2}^{y_{i2}}
  \pi_{3}^{y_{i3}}
  \pi^{*N_{i}- y_{i.}} \right)
 \frac{e^{-\lambda} \lambda^N}{N!} \right\}
\end{equation}

The function \code{multinomPois} can be used to maximize this likelihood.

For multinomial-Poisson sampling methods, the actual observations are
an underlying categorical detection variable with $M \leq J$ levels so
that the $J$-dimensional $\mathbf Y_{i}$ is derived from the
$M$-dimensional raw counts in some sampling method-specific manner.
Thus, it is necessary to model the detection at the raw observation
level, denoted $p_{ik}$ for $k=1,2,\dots,M$ at site $i$.  Then we
derive the multinomial cell probabilities $\boldsymbol \pi_{i}$
through the sampling technique-specific relationship
$\pi_{ij}=g(p_{ik})$ where $p_{ik}$ is the underlying probability of
detection and $g$ is some sampling method-specific function.  

Thus, the only two requirements to adapt \um's general multinomial Poisson
modeling to a new sampling method is to specify $g$ and a binary 0-1
matrix that describes the mapping of elements of
$\mathbf p_{i} = (p_{i1},\dots,p_{iR})'$ to elements of
$\boldsymbol \pi_{i}$.  This mapping matrix, referred to in
\um\ as \code{obsToY}, is necessary to consistently clean
missing values from the data and relate observation-level covariates
with the responses.  The ($j$,$k$)th element of
\code{obsToY} is 1 only if $p_{ik}$ is involved in the computation of
$\pi_{ij}$.  The detection function $g$ is called \code{piFun} in \um.

Covariates may be included in either the
state (here, abundance) or detection levels, through $\mathbf p_{i}$
(not $\boldsymbol \pi_{i}$).
\begin{gather}
  \log(\lambda_i) = \mathbf x_i' \mathbf \beta,
\end{gather}
where $\mathbf x_i$ is a vector of site-level covariates and $\mathbf \beta$
is a vector of their corresponding effect parameters.  Similarly, the
probability of detection can be modeled with
\begin{gather}
  \logit(p_{ij}) = \mathbf v_{ij}' \mathbf \alpha,
\end{gather}
where $\mathbf v_{ij}$ is a vector of observation-level covariates and
$\mathbf \alpha$ is a vector of their corresponding effect parameters.

We now describe two common sampling methods that can be modeled
with the multinomial-Poisson model: removal sampling and double
observer sampling.  These two methods are included in \um, but
additional methods may easily be specified by defining a user-specified 
\code{piFun} function and \code{obsToY} matrix.

\subsubsection{Removal sampling}

Popular in fisheries, removal sampling is implemented by visiting a
sample of $M$ sites $J$ times each and trapping and removing
individuals at each visit with the same effort.  Thus, $Y_{ij}$ is the
number of individuals captured at the $j$th visit for $j=1,2,\dots,J$.

Then, we can specify $g$ for removal sampling as follows.  The
probability of an individual at site $i$ being captured on the first
visit is $\pi_{i1} = p_{i1}$.  The probability of capture on the $j$th
visit is
\begin{equation}
  \pi_{ij} = \prod_{k=1}^{j-1}(1 - p_{ik})p_{ij},
\end{equation}
for $j=2,\dots,J$ and the probability of not being sampled is
\begin{equation}
  \pi_{i,J+1} = \prod_{j=1}^{J}(1-p_{ij})
\end{equation}
Or, equivalently,
\begin{equation}
  \mathbf \pi_i =
  \begin{pmatrix}
    p_{i1} \\
    (1-p_{i1})p_{i2} \\
    \vdots \\
    \prod_{j=1}^J(1-p_{ij})p_{iJ}
  \end{pmatrix}
\end{equation}
Thus, the mapping matrix is an $J \times J$  matrix with ones in
the upper triangle,
\begin{equation}
  \begin{pmatrix}
    1 & 1 & \dots & 1 \\
    0 & 1 & \dots & 1 \\
    \vdots & & \ddots & \vdots \\
    0 & 0 & \dots  & 1
  \end{pmatrix}
\end{equation}


\subsubsection{Double observer sampling}
\label{sec:double-observ-sampl}

Double observer sampling involves collecting data by a team of two surveyors
simultaneously visiting a site.  Each observer records a list of detected 
animals and at the end of the survey, the two observers attempt to reconcile
their counts.  If individuals are not uniquely marked, this may be a difficult 
task in practice; however, assuming that individuals can be distinguised, the 
data at each site are a vector of length three $\mathbf Y_i$,
corresponding to the numbers of individuals seen by only observer one,
only observer two, and both observers.  Thus, for double observer sampling, 
$g$ is
defined as follows.
\begin{equation}
  \mathbf \pi_i =
  \begin{pmatrix}
    p_{i1}(1-p_{i2}) \\
    (1-p_{i1})p_{i2} \\
    p_{i1}p_{i2} \\
    (1-p_{i1})(1-p_{i2}).
  \end{pmatrix}
\end{equation}
The \code{obsToY} mapping matrix for double observer sampling is the
following $3 \times 2$ matrix.
\begin{equation}
  \begin{pmatrix}
    1 & 0 \\
    0 & 1 \\
    1 & 1 
  \end{pmatrix}
\end{equation}


\subsection{Multi-season occupancy data}

Sometimes the study objective is to understand the evolution of
the occupancy state over time. To obtain such information researchers conduct 
repeated occupancy studies (see Section~\ref{sec:occ}) at the same sample of 
sites over consecutive seasons \citep{MacKenzie2003}.  They then seek to estimate
probabilities of colonization ($\gamma_{it}$) and extinction
($\epsilon_{it}$), where colonization is the change of an unoccupied
site to occupied and extinction if the change of an occupied site to
unoccupied.  If the occupancy status is assumed to evolve according to
a Markov process, then a 2-state finite hidden Markov model describes
these data.  Let $Y_{itj}$ denote the observed animal occurrence
status at visit $j$ during season $t$ to site $i$.  Then
\begin{gather}
  Z_{i1} \sim \Bern(\psi) \\
  Z_{it} \sim
  \begin{cases}
    \Bern(\gamma_{i(t-1)}) & \text{if $Z_{i(t-1)} = 0$} \\
    \Bern(1-\epsilon_{i(t-1)}) & \text{if $Z_{i(t-1)} = 1$}
  \end{cases}, \\
  \text{for $t=2,3,\dots,T$} \notag \\
  Y_{itj} | Z_{it} \sim \Bern(Z_{it} p_{itj})
\end{gather}

To define the likelihood of this model, let $\phi_0 = (\psi, 1-\psi)$ and 

\begin{equation}
  \theta_{{\bf Y_{it}}} =
  \begin{pmatrix}
    \prod_{j}^{J} p I(Y_{ijt}=0)(1-p_{ijt}) \\
    I(\sum_{j}^{J} Y_{ijt}=0) \\
  \end{pmatrix}
\end{equation}

when I({\it arg}) is the indicator function returning 1 if {\it arg} is 
satisfied and 0 otherwise. Furthermore, let  the matrix of one-step Markov 
transition probabilities be 

\begin{equation}
  \Phi_t =
  \begin{pmatrix}
    1-\epsilon & \epsilon \\
    1-\gamma & \gamma\\
  \end{pmatrix}
\end{equation}

The likelihood is thus

\begin{equation}
L(Y_{ijt}| p,\phi,\epsilon,\gamma) = 
 \prod_{i}^{R} \left\{
    \phi_0 \left\{ \prod_{t}^{T-1} \Phi_t \theta_{Y_{it}}  
        \right\} \theta_{Y_{iT}} \right\},
\end{equation}

which is maximized by the \code{colext} function. 


\section[unmarked usage]{\pkg{unmarked} usage}
\label{sec:unmarked-usage}

\um\ provides data structures, fitting syntax, and post-processing that form a
cohesive framework for site-based ecological data analysis.  In order
to achieve these goals, \um\ uses the S4 class system
\citep{Chambers2008}. As \rlang's most modern system of class-based
programming, S4 allows customization of functions, referred to as
methods, to specific object classes and superclasses. For example,
when the generic \code{predict} method is called with any \um\ model
fit object as an argument, the actual \code{predict} implementation
depends on the specific model that was fit.  Use of class-based
programming can provide more reliable and maintainable software while
also making the program more user-friendly \citep{Chambers2008}.


\subsection{Preparing data}
\label{sec:data-requirements}

\um\ uses a custom S4 data structure called the \code{unmarkedFrame}
to store all data and metadata related to a sampling survey.  Although this at
first appears to add an extra layer of work for the user, there are
several reasons for this design choice.  The multilevel structure of
the models means that standard rectangular data structures such as 
\code{data.frame}s or matrices are not suitable for storing the data.  For
example, covariates might have been measured separately at the site
level and at the visit level.  Furthermore, the length of the response
vector $\mathbf Y_{i}$ at site $i$ might differ from the number of
observations at the site as in the multinomial Poisson model.  In some 
cases, metadata of arbitrary dimensions may need to be associated with the 
data.  For example, in distance sampling it is necessary to store the units 
of measure and the survey design type.  Aside
from these technical reasons, \citet{Gentleman2009} pointed out that
the use of such portable custom data objects can simplify future
reference to previous analyses, an often neglected aspect of research.
Repeated fitting calls using the same set of data require less code
repetition if all data is contained in a single object.  Finally,
calls to fitting functions have a cleaner appearance with a more
obvious purpose when the call is not buried in data arguments.  The
parent data class is called an unmarkedFrame and each \um\
fitting function has its own data type that extends the
unmarkedFrame.  Thus, the first step when using \um\ is to
import data into the proper type of unmarkedFrame.  To ease
this step, \um\ includes several helper functions to automatically
convert data into an unmarkedFrame: \code{csvToUMF} which
imports data directly from a comma-separated value text file,
\code{formatWide} and \code{formatLong} which convert data from data
frames, and the family of unmarkedFrame constructor functions.

An \code{unmarkedFrame} object contains components referred to as slots, which hold 
the data and metadata. All \code{unmarkedFrame} objects contain a slot for the 
observation matrix \code{y}, a \code{data.frame} of site-level covariates 
\code{siteCovs}, and a \code{data.frame} of observation-level covariates 
\code{obsCovs}.  The \code{y} matrix is the only required unmarkedFrame slot. 
Each row of \code{y} contains either the observed counts or presence-absence
data at each of the $R$ sites.  \code{siteCovs} is an $M$-row \code{data.frame} 
with a column for each site-level covariate.  \code{obsCovs} is an $MJ$-row 
\code{data.frame} with a column for each observation-level covariate.  Thus 
each row of \code{obsCovs} corresponds to a particular observation, with the 
order corresponding to site varying slower and observation within site
varying faster.  Both \scovs\ and \ocovs\ can contain \code{NA}
values corresponding to unbalanced or missing data.  If any terms in the model
specification are missing for that observation, \um\
automatically removes observations.  \um\ provides
constructor functions to make creating unmarkedFrames straightforward.
For each specific data type, specific types of unmarkedFrames extend
the basic unmarkedFrame to handle model-specific nuances.

\subsubsection{Importing repeated count data}

Here is an example of creating an unmarkedFrame for repeated count data
(Section~\ref{sec:repeated-count-data}). First, load the included data set of 
Mallard ({\it Anas platyrhynchos}) point counts from \citet{Kery2005}.

<<>>=
library(unmarked)
data(mallard)
@ 

Loading the mallard data makes three objects availble within the \rlang\ 
workspace. The matrix \code{mallard.y} contains the number of mallards counted
at each of $M=239$ sites on $J=3$ visits.  It is formatted such that each 
row is a site and each columnn corresponds to a visit.  The site-level 
covariates are column vectors in the \code{mallard.site} \code{data.frame}, which 
has $M$ rows. The observation-level covariates are a list object with separate 
$M \times J$ matrices for each observation-level covariate.  The unmarkedFrame 
constructors can accept \ocovs\ in this list format or as a \code{data.frame} in the 
format described above.

The following call to \code{unmarkedFramePCount} organizes the observations 
and covariates into an object that can be passed to the data argument of
the fitting function \code{pcount}.

<<>>=
mallardUMF <- unmarkedFramePCount(y = mallard.y, siteCovs = mallard.site, obsCovs = mallard.obs)
@

Printing unmarkedFrames shows them as \code{data.frame}s to make it easier to verify 
that the data were converted correctly. Here we show the first five rows only. 

<<>>=
head(mallardUMF, 5)
@ 

The site-level covariates are elevation (elev), transect length (length), 
and the proportion of forest covering the site (forest).  The two 
observation-level covariates are a measure of survey effort (ivel) and the date 
of the survey (date).  Note that these variables are standardized to 
mean of 0 and unit variance.  We can also check data contents with a quick summary.

<<>>=
summary(mallardUMF)
@ 

The summary reveals that only 40 sites have at least one detection -- these 
data are in fact very sparse as is commonplace in ecological statistics. The 
tabulation of y observations provides additional evidence of sparse counts, 
with no mallards being detected at 576 of the surveys. The 58 NA values 
correspond to missing data. 


\subsubsection{Importing removal sampling data}

To illustrate the slightly different syntax for removal sampling data example, 
we will import data from a removal survey of ovenbirds 
({\it Seiurus aurocapillus}) described by \citet{Royle2004a}.  The data consist 
of a list named \code{ovendata.list} with 
a matrix \code{data} containing the removal counts for 4 visits and a 
\code{data.frame} called \code{covariates} containing site-level covariates 
information.

<<>>=
data(ovendata)
head(ovendata.list$data, 10)
@ 

Each row of the response matrix corresponds to a site, and each column is a 
removal occasion. Thus, it is evident that ovenbirds were detected at three of 
the first ten sites and no new birds were detected after the first removal 
occasion.  The only additional specification required when importing removal 
data is to specify the particular type of multinomial-Poisson data as
\code{removal} via the \code{type} argument.

<<>>=
ovenFrame <- unmarkedFrameMPois(ovendata.list$data, 

siteCovs = ovendata.list$covariates, type = "removal")
summary(ovenFrame)
@ 

\subsubsection{Preparing multi-season occupancy data}

The data structures are more complex when surveys occurred during more than one
season. In this case, the covariates can occur at the site-, season-, and
observation-levels. The following toy examples demonstrates how to prepare data
for the \code{colext} fitting function if there were only four sites, two
visits per season, and three seasons.

<<>>=
M <- 4
J <- 2
T <- 3
y <- matrix(0:1, nrow=M, ncol=J*T)
umf <- unmarkedMultFrame(y=y, numPrimary=T)
summary(umf)
@

The function \code{unmarkedMultFrame} accepts \scovs\ and \ocovs\ like all 
other unmarkedFrame classes, and it also has an argument \code{yearlySiteCovs}
that can accept a list of $M \times T$ \code{data.frame}s containing season-level
covariates.

\subsection{Manipulating unmarkedFrames}
\label{sec:manip}

The various components of \code{unmarkedFrames} can be extracted and subsetted in
a manner similar to the methods used to manipulate standard \rlang\ objects.  
Subsetting can be accomplished using the `bracket' notation. For example, 
the first five rows of data and the first two removal occasions can be 
extracted from the ovenbird removal study using

<<eval=true>>=
ovenFrame[1:5, 1:2]
@

In some cases, the covariate data may need to be manipulated after the 
\code{unmarkedFrame} has been created. The following code demonstrates 
how to extract the site-level covariates, standardize those that are 
continuous (columns 2 and 3), and reinsert them back into the 
\code{unmarkedFrame}.

<<>>=
sc <- siteCovs(ovenFrame)
sc[,2:3] <- scale(sc[,2:3])
siteCovs(ovenFrame) <- sc
@



\subsection{Fitting models}
\label{sec:fitting-models}

As introduced in Section~\ref{sec:models-impl-unmark}, each model has a
corresponding fitting function.  For example, to fit a repeated count
model, we call \code{pcount}.  Table~\ref{tab:models} provides a
summary of all models that \um\ currently fits.  With the exception of the 
`open' population models (\code{colext}, \code{gmultmix}, and 
\code{pcountOpen}), all fitting functions use a double right-hand sided 
formula syntax that expresses the hierarchical model and data structures.  
Specifically, covariates affecting the detection process are specified 
following the first tilda, and covariates of the state process follow the 
second tilda. No left-hand side of the formula is specified because the 
unmarkedFrame defines the response variable uniquely as the \code{y} slot.

\subsubsection{Fitting a repeated count model}

Continuing the Mallard example, the following call to \code{pcount} fits a 
binomaial-Poisson mixture model (Section~\ref{sec:repeated-count-data}).  The 
following code specifies that detection probability $p$ should be modeled by 
day of year, including a quadratic term.  We also wish to model abundance 
using elevation and proportion of area forested.  As described in 
Section~\ref{sec:repeated-count-data}, covariates of detection are on the 
logit-scale and covariates of abundance are on the log scale for the 
repeated count model.

<<cache=TRUE>>=
fm.mallard.1 <- pcount(~ date + I(date^2) ~ elev + forest, data = mallardUMF)
fm.mallard.1
@

%%%% This interpretation comes before model results are presented
This initial fit suggests that Mallard abundance decreases with
increasing elevation and forest.  It also looks like a linear model
might suffice for the detection model, so we subsequently fit the
linear detection model.


<<cache=TRUE>>=
fm.mallard.2 <- pcount(~ date ~ elev + forest, data = mallardUMF)
fm.mallard.2
@

This seems to be a better model according to both the Wald p-value and
AIC.  Thus detection appears to decrease during the course of a year.



\subsubsection{Fitting a multinomial-Poisson model}

Here we demonstrate fitting a multinomial-Poisson mixture model to removal 
sampling data.  The Ovenbird data has no observation-level covariates, so 
detection probability is assumed constant across visits.  It is not necessary
to specify that removal sampling was used when fitting the model
because this information is already stored in the \code{ovenFrame} data.
We model abundance as a function of understory forest coverage (\code{ufp})
and average basal tree area (\code{trba}).

<<cache=true>>=
fm.oven.1 <- multinomPois(~ 1 ~ ufp + trba, ovenFrame)
fm.oven.1
@ 

\subsection{Examining model fits}
\label{sec:examining-model-fits}

Objects returned by \um's fitting functions also make use of the S4
class system.  All model fit objects belong to the unmarkedFit parent
class.  Thus, common operations such as extracting coefficient
estimates, covariance matrices for estimates, and confidence intervals
have been adapted to behave similar to \rlang's base functions.

For example, we can extract estimated coefficients either from the
entire model, or from the state or detection levels by specifying the
\code{type} argument.

<<>>=
coef(fm.mallard.2)
coef(fm.mallard.2, type = "state")
@ 

To check which types are available for a model, use the \code{names} method.

<<>>=
names(fm.mallard.2)
@ 

Similarly, the \code{vcov} function extracts the covariance matrix of
the estimates, using the observed Fisher information by default.

<<>>=
vcov(fm.mallard.2)
@ 

\code{vcov} also accepts a \code{type} argument, as does the convenience method 
\code{SE}, which returns standard errors from the square root of the diagonal 
of the covariance matrix.

<<>>=
SE(fm.mallard.2, type = "state")
@ 

Nonparametric bootstrapping can also be used to estimate the
covariance matrix. \um\ implements a two-stage bootstrap in which the
sites are first drawn with replacement, and then within each site, the
observations are drawn with replacement.  First, bootstrap draws must
be taken using the \code{nonparboot}.  \code{nonparboot} returns a new
version of the unmarkedFit object with additional bootstrap sampling
information.  Thus, this new fit must be stored, either in a new fit
object or the same one, and then subsequently queried for bootstrap
summaries.  In the following, bootstrapping can be quite slow.  For
these examples, we illustrate with the removal sampling data simply
because computations are much faster.  However, bootstrapping is
available for any of the models that \um\ fits.

<<cache=TRUE>>=
set.seed(1234)
fm.oven.1 <- nonparboot(fm.oven.1, B = 100)
@ 

<<>>=
SE(fm.oven.1, type = "state")
SE(fm.oven.1, type = "state", method = "nonparboot")
@ 

It looks like bootstrapping and asymptotic standard errors are close.
The summary now states the number of bootstrap samples.

<<>>=
summary(fm.oven.1)
@ 

Additional bootstrap samples can be drawn by calling \code{nonparboot} again.
<<cache=TRUE>>=
fm.oven.1 <- nonparboot(fm.oven.1, B = 100)
@ 

Confidence intervals can be requested for the coefficients at either
stage of the model.  By default, the asymptotic normal approximation
is used.

<<>>=
confint(fm.oven.1, type = "state", level = 0.95)
@ 

Profile confidence intervals are also available upon request.  This
can take some time, however, because for each parameter, a nested
optimization within a root-finding algorithm is being used to find the
profile limit.

<<cache=TRUE>>=
ci <- confint(fm.oven.1, type = "state", level = 0.95, method = "profile") 
@ 
<<>>=
ci
@ 

The profile confidence intervals and normal approximations are quite
similar here.

\subsubsection{Linear combinations of estimates}

Often, meaningful hypotheses can be addressed by estimating linear
combinations of coefficient estimates.  Linear combinations of coefficient
estimates can be requested with \code{linearComb}.

Continuing the Ovenbird example, the following code estimates the
log-abundance rate for a site with \code{ufp = 0.5} and \code{trba
  = 0}.

<<>>=
(lc <- linearComb(fm.oven.1, type = "state", coefficients = c(1, 0.5, 0)))
@ 

Multiple sets of coefficients may be supplied as a matrix.  The
following code requests the estimated log-abundance for sites with
\code{ufp = 0.5} and \code{trba = 1}.

<<>>=
(lc <- linearComb(fm.oven.1, type = "state", 
    coefficients = matrix(c(1, 0.5, 0, 1, 1, 0), 2, 3, byrow = TRUE)))
@ 

Standard errors and confidence intervals are also available for linear
combinations of parameters.  By requesting nonparametric bootstrapped
standard errors, \um\ uses the samples that were drawn earlier.

<<>>=
SE(lc)
SE(lc, method = "nonparboot")
confint(lc)
@ 

\subsubsection{Back-transforming linear combinations of coefficients}

Estimates of linear combination back-transformed to the native scale
are likely to be more interesting than the direct linear combinations.
For example, the logistic transformation is applied to estimates of
detection rates, resulting in a probability bound between 0 and
1. This is accomplished with the \code{backTransform}.  Standard
errors of back-transformed estimates are estimated using the delta
method.  Confidence intervals are estimated by back-transforming the
confidence interval of the original linear combination.

<<>>=
(btlc <- backTransform(lc))
SE(btlc)
SE(btlc, method = "nonparboot")
confint(btlc)
@ 


\subsubsection{Model selection}

\pkg{unmarked} performs AIC-based model selection for structured lists of 
unmarkedFit objects.  To demonstrate, we fit a few more models to the Ovenbird
removal data, including all an interaction model, two models with
single predictors, and a null model with no predictors.

<<cache=true>>=
fm.oven.2 <- update(fm.oven.1, formula = ~ 1 ~ ufp*trba)
fm.oven.3 <- update(fm.oven.1, formula = ~ 1 ~ ufp)
fm.oven.4 <- update(fm.oven.1, formula = ~ 1 ~ trba)
fm.oven.5 <- update(fm.oven.1, formula = ~ 1 ~ 1)
@ 

Now, we can organize the fitted models with the \code{fitList} function and
the use the \code{modSel} method to rank the models by AIC.

<<>>=
fmList <- fitList(Global=fm.oven.2, additive = fm.oven.1, ufp=fm.oven.3, trba=fm.oven.4, Null=fm.oven.5)
modSel(fmList)
@ 

It looks like the best model includes only tree basal area as a
predictor of abundance.  We can examine this relationship using
the \code{predict} method (Figure~\ref{fig:pred}).


\begin{figure}[ht]
  \centering
<<eval=true,echo=false,fig=true>>=
preddata <- predict(fm.oven.4, type = "state", appendData = TRUE)
library(ggplot2)
print(qplot(trba, Predicted, data = preddata, geom = "line", 
      xlab = "Scaled Basal Tree Area",
      ylab = "Estimated Abundance") + 
  geom_ribbon(aes(x = trba, ymin = lower, ymax = upper),
              alpha = 0.1) + theme_bw())
@ 
\caption{Examine estimated abundance for Ovenbird removal data.  Band
  is 95\% confidence interval.}
\label{fig:pred}
\end{figure}

<<eval=FALSE,fig=FALSE>>=
preddata <- predict(fm3, type = "state", appendData = TRUE)
library(ggplot2)
qplot(trba, Predicted, data = preddata, geom = "line", 
      xlab = "Scaled Basal Tree Area",
      ylab = "Estimated Abundance") + 
  geom_ribbon(aes(x = trba, ymin = lower, ymax = upper),
              alpha = 0.1) + theme_bw()
@ 



\code{predict} functions much like \code{linearComb} except that new data can be
passed to it as a \code{data.frame} rather than a design matrix. When the first 
argument given to predict is a list of models created by \code{fitList}, 
\code{predict} computes model-averaged predictions, which may be
useful in the presence of high model selection uncertainty.  




\subsubsection{Parametric bootstrap for goodness of fit}

To conduct goodness of fit tests, \um\ provides a generic parametric 
bootstrapping function.  It simulates data from the fitted model and 
applies a user-defined function that returns a fit-statistic such as the 
sum of squared residuals.  Beyond serving as a tool to evaluate goodness of fit, 
\code{parboot} can be used to characterize uncertainty in any derived quantity 
of interest. Here we compute a chi-squared statistic to evaluate 
goodness of fit.

%suppress progress report. Probably should add option to argument list too.
<<cache=true>>=  
set.seed(1234)
chisq <- function(fm) {
    observed <- getY(fm@data)
    expected <- fitted(fm)    
    sum((observed - expected)^2 / expected)
    }
pb <- parboot(fm.oven.1, statistic = chisq, nsim = 20)
pb
@ 

<<eval=FALSE>>= 
plot(pb, main = "")
@ 

\begin{figure}[H]
  \centering
<<fig=TRUE,echo=FALSE>>=
set.seed(1234)
plot(pb, main = "", xlab=expression(chi^2))
@ 
\caption{Graphically assess model fit by parametric bootstrapping.  The dashed 
line is the observed chi-squared statistic. The histogram approximates the 
expected sampling distribution}
\label{fig:pb}
\end{figure}


The above call to \code{plot} with a parametric bootstrap object as
the argument produces a useful graphic for assessing goodness of fit
(Figure~\ref{fig:pb}).  The plot suggests that the model can sufficiently
explain these data.


\section[Future directions for unmarked development]{Future directions for \um\ development}
\label{sec:future-direct-unmark}

\um\ has become a stable and useful platform for the analysis of ecological 
data, but several areas of development could improve its utility.  First, new 
models need to be added to cover the range of sampling techniques and 
population dynamics commonly encountered. Table 3 illustrates the current 
gaps that need to be filled. In most cases, models to fill these gaps have not 
been developed so more research is needed.  

\begin{table}[H] \small
\begin{tabular}{lccc}
\hline
& \multicolumn{3}{c}{Population Dynamics} \\
\cline{2-4} 
Sampling method             & Closed              & Open to movement & Open to demographic processes \\
\hline                            
Occurrence sampling         & \code{occu}         & --               & \code{colext} \\
Repeated counts             & \code{pcount}       & --               & \code{pcountOpen} \\
Removal sampling, \\double observer sampling,  & \code{multinomPois} & \code{gmultmix}  & -- \\
and other multinomial designs \\
Distance-sampling           & \code{distsamp}     & --               & -- \\
\hline
\end{tabular}
\caption{Model fitting functions classified by sampling method and population dynamics.}
\label{tab:modelspace}
\end{table}


Second, each of the models in \um\ assumes independence among sites. However, 
ecologists often use sampling methods such as cluster sampling that induce 
spatial dependence. Typically, this is done for logistical convenience, but 
because few methods are available to account for spatial correlation and 
imperfect detection probability, the spatial dependence is often ignored.  
Rather than this being a weakness of the sampling design, we envision that 
this dependence can be used as information regarding the spatial distribution
of individuals.  

Finally, Bayesian estimation could be implemented for many of these models.  An 
important advantage of Bayesian analysis over classical methods is that the 
latent abundance or occurence variables can be treated as formal parameters.  
Thus posterior distriutions could easily be calculated for derived parameters 
such as the proportion of sites occupied.  Bayesian analysis also would provide 
a natural framework for incorporating additional sources of random variation.  
For example, one could model heterogeneity among sites not accounted for by 
covariates alone.  

\section*{Acknowledgements}

The authors thank Andy Royle of the United States Geological Survey's
Patuxent Wildlife Research Center, who provided initial funding and
inspiration for this work.

%%\bibliographystyle{jss}
\bibliography{unmarked}

\end{document}
